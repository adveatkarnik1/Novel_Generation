{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7327794,"sourceType":"datasetVersion","datasetId":4253300}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center> **Novel Creation using PyTorch in a Decoder only Fashion**</center>\n\n- The series **Percy Jackson and the Olympians** by **Rick Riordan** was used for Model Training (I absolutely love the series)\n\n- **Andrej Karpathy** sir's and **Josh Starmer** sir's material on Youtube has been used as reference material\n\n- This project is strictly for a learning experience\n\n- Please note that no copyrights were meant to be broken and in case of any unintended violations, please contact me and I will take down this project\n\n- The A100 GPU was used for this model's training, thus GOogle Colab Pro was used\n","metadata":{"id":"tU619q61lRZP"}},{"cell_type":"markdown","source":"# Sections\n\n1. Importing Libraries\n2. Setting Hyperparameters\n3. Loading Text Files (PDFs) and cleaning\n4. Encoding Text\n5. Obtaining Batches\n6. Implementing a HEAD of Self-Attention\n7. Implementing Multi-head Attention\n8. FeedForward and Layer Normalisation for Residual Connection in a Block\n9. Pre-Block Creation\n10. Post-Block Creation\n11. Putting it all together (Transformer)\n12. Instantiation and Model Training\n13. Saving, Calculating Size and Loading Models Weights\n","metadata":{"id":"RaYjx98dlRZS"}},{"cell_type":"markdown","source":"# 1. Importing Libraries\n\nThe framework used was PyTorch thus relevant modules need to be imported","metadata":{"id":"tek2C6fglRZT"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"_EmThiADl84G","execution":{"iopub.status.busy":"2024-01-10T15:44:07.904996Z","iopub.execute_input":"2024-01-10T15:44:07.905544Z","iopub.status.idle":"2024-01-10T15:44:07.910154Z","shell.execute_reply.started":"2024-01-10T15:44:07.905506Z","shell.execute_reply":"2024-01-10T15:44:07.909138Z"},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a561fd1-0265-47b9-96f0-f624d5bd12d0","trusted":true},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Mounted at /content/drive\n"}]},{"cell_type":"code","source":"!pip install PyPDF2\n!pip install torchsummary\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom tqdm import tqdm\nfrom PyPDF2 import PdfReader\nimport os\nfrom google.colab import files","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7SLNxiYDlRZT","outputId":"b3834605-f514-42c0-dab4-afde74318aba","execution":{"iopub.status.busy":"2024-01-10T15:44:07.945061Z","iopub.execute_input":"2024-01-10T15:44:07.945365Z","iopub.status.idle":"2024-01-10T15:44:33.928290Z","shell.execute_reply.started":"2024-01-10T15:44:07.945332Z","shell.execute_reply":"2024-01-10T15:44:33.927172Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting PyPDF2\n\n  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hInstalling collected packages: PyPDF2\n\nSuccessfully installed PyPDF2-3.0.1\n\nRequirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"}]},{"cell_type":"markdown","source":"# 2. Setting Hyperparamters\n\n- **Batch Size**: Helps in parallelism by utilising the the multiple cores of the GPU simultaneously for independent processing\n- **Block Size**: Context window to pick training samples from\n- **max_iters**: The maximum epochs used for training\n- **eval_interval**: The interval after which loss is to be estimated during training\n- **learning_rate**: The magnitude by which we want to update our model weights\n- **device**: Allows for the usage of GPU, if available\n- **eval_iters**: Used to estimate loss, determines the number of batches of data to select (X), predictions to make (Y') and then evaluate with actual values (Y).The loss is calculated based on this Y' and Y\n- **n_embd**: The size of the embedding, converts the OHE representation of the character into a vec of n_embd dimensions\n- **n_head**: Number of heads of self-attention (for multi-head attention)\n- **n_layer**: Number of Blocks in the transformer blocks in the GPT model\n- **dropout**: Values between 0 and 1 represent the probability of keeping a neuron's output during training","metadata":{"id":"Ne19NXt-lRZU"}},{"cell_type":"code","source":"batch_size = 128\nblock_size = 512\nmax_iters = 25000\neval_interval = 1000\nlearning_rate = 3e-4\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 250\nn_embd = 512\nn_head = 16\nn_layer = 4\ndropout = 0.2","metadata":{"id":"alnnbzyblRZV","execution":{"iopub.status.busy":"2024-01-10T15:44:33.930447Z","iopub.execute_input":"2024-01-10T15:44:33.930788Z","iopub.status.idle":"2024-01-10T15:44:33.962586Z","shell.execute_reply.started":"2024-01-10T15:44:33.930755Z","shell.execute_reply":"2024-01-10T15:44:33.961516Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 3. Loading Text FIles (PDFs)\n\nAll 5 books of the series \"Percy Jackson and the Olympians\" were used\n\nA list of strings is used to store the text","metadata":{"id":"DqaZvLZElRZW"}},{"cell_type":"code","source":"output_texts = []\n# path = \"/content/drive/MyDrive/Books\"\npath = \"/kaggle/input/percy-jackson\"","metadata":{"id":"jynBfantlRZW","execution":{"iopub.status.busy":"2024-01-10T15:44:33.963796Z","iopub.execute_input":"2024-01-10T15:44:33.964077Z","iopub.status.idle":"2024-01-10T15:44:33.980700Z","shell.execute_reply.started":"2024-01-10T15:44:33.964053Z","shell.execute_reply":"2024-01-10T15:44:33.979603Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"counter =0\nfor pdf_file in os.listdir(path):\n\n    if pdf_file.endswith(\".pdf\"):\n        counter+=1\n        print(\"BOOK\",counter,\"\\n\\n\\n\")\n        pdf_path = os.path.join(path, pdf_file)\n\n        reader = PdfReader(pdf_path)\n        text = \"\"\n\n        for i, page in enumerate(tqdm(reader.pages, desc=f\"Processing {pdf_file}\", unit=\"page\")):\n            text += page.extract_text() + \"\\n\"\n\n            # Check if the current page is a multiple of 7\n            if (i + 1) % 35 == 0:\n                print(f\"Scanned completely up to page {i + 1} of {pdf_file}\")\n\n        # Append the final text to the list\n        output_texts.append(text)\n        print(\"\\n\\n\\n\\n\\n\\n\\n\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rReB-MC-lRZX","outputId":"cee02c81-a050-4a02-990d-38d991699c62","execution":{"iopub.status.busy":"2024-01-10T15:44:33.983586Z","iopub.execute_input":"2024-01-10T15:44:33.983931Z","iopub.status.idle":"2024-01-10T15:45:47.439230Z","shell.execute_reply.started":"2024-01-10T15:44:33.983905Z","shell.execute_reply":"2024-01-10T15:45:47.438150Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":"BOOK 1 \n\n\n\n\n\n\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  11%|█         | 40/370 [00:01<00:13, 24.73page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 35 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  20%|██        | 74/370 [00:03<00:14, 21.06page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 70 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  29%|██▊       | 106/370 [00:04<00:10, 25.27page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 105 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  39%|███▉      | 145/370 [00:06<00:10, 21.04page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 140 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  48%|████▊     | 179/370 [00:07<00:07, 26.39page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 175 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  57%|█████▋    | 212/370 [00:09<00:07, 21.77page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 210 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  67%|██████▋   | 249/370 [00:11<00:04, 25.54page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 245 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  76%|███████▋  | 283/370 [00:12<00:03, 22.89page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 280 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  85%|████████▌ | 316/370 [00:14<00:02, 20.27page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 315 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf:  96%|█████████▌| 354/370 [00:15<00:00, 25.77page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 350 of PJ_b1.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b1.pdf: 100%|██████████| 370/370 [00:16<00:00, 22.50page/s]\n"},{"output_type":"stream","name":"stdout","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBOOK 2 \n\n\n\n\n\n\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b2.pdf:  19%|█▉        | 36/192 [00:01<00:09, 16.58page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 35 of PJ_b2.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b2.pdf:  37%|███▋      | 71/192 [00:04<00:08, 13.58page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 70 of PJ_b2.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b2.pdf:  56%|█████▌    | 107/192 [00:06<00:04, 17.48page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 105 of PJ_b2.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b2.pdf:  73%|███████▎  | 141/192 [00:08<00:03, 16.65page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 140 of PJ_b2.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b2.pdf:  92%|█████████▏| 177/192 [00:10<00:00, 16.73page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 175 of PJ_b2.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b2.pdf: 100%|██████████| 192/192 [00:11<00:00, 16.70page/s]\n"},{"output_type":"stream","name":"stdout","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBOOK 3 \n\n\n\n\n\n\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b3.pdf:  29%|██▊       | 59/207 [00:00<00:00, 191.62page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 35 of PJ_b3.pdf\n\nScanned completely up to page 70 of PJ_b3.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b3.pdf:  67%|██████▋   | 139/207 [00:00<00:00, 196.84page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 105 of PJ_b3.pdf\n\nScanned completely up to page 140 of PJ_b3.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b3.pdf: 100%|██████████| 207/207 [00:01<00:00, 193.39page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 175 of PJ_b3.pdf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBOOK 4 \n\n\n\n\n\n\n"},{"output_type":"stream","name":"stderr","text":"\n\nProcessing PJ_b4.pdf:  16%|█▌        | 38/234 [00:01<00:06, 29.23page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 35 of PJ_b4.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b4.pdf:  32%|███▏      | 76/234 [00:02<00:05, 28.52page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 70 of PJ_b4.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b4.pdf:  46%|████▌     | 107/234 [00:03<00:04, 31.59page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 105 of PJ_b4.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b4.pdf:  62%|██████▏   | 144/234 [00:04<00:03, 29.88page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 140 of PJ_b4.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b4.pdf:  76%|███████▋  | 179/234 [00:06<00:01, 28.84page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 175 of PJ_b4.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b4.pdf:  91%|█████████▏| 214/234 [00:07<00:00, 30.02page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 210 of PJ_b4.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b4.pdf: 100%|██████████| 234/234 [00:08<00:00, 29.19page/s]\n"},{"output_type":"stream","name":"stdout","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBOOK 5 \n\n\n\n\n\n\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b5.pdf:  24%|██▎       | 47/200 [00:00<00:01, 90.60page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 35 of PJ_b5.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b5.pdf:  44%|████▎     | 87/200 [00:00<00:01, 89.86page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 70 of PJ_b5.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b5.pdf:  58%|█████▊    | 117/200 [00:01<00:00, 93.17page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 105 of PJ_b5.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b5.pdf:  80%|███████▉  | 159/200 [00:01<00:00, 99.46page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 140 of PJ_b5.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b5.pdf:  90%|████████▉ | 179/200 [00:02<00:00, 77.66page/s]"},{"output_type":"stream","name":"stdout","text":"Scanned completely up to page 175 of PJ_b5.pdf\n"},{"output_type":"stream","name":"stderr","text":"Processing PJ_b5.pdf: 100%|██████████| 200/200 [00:02<00:00, 90.02page/s]"},{"output_type":"stream","name":"stdout","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"output_type":"stream","name":"stderr","text":"\n"}]},{"cell_type":"markdown","source":"> Finding **starting points** for each book as the introduction section is not needed (doesn't provide any useful information)\n\n> The actual useful sections start from Chapter 1","metadata":{"id":"W8i786OGlRZY"}},{"cell_type":"code","source":"starting_index= [pdf.find(\"ONE\") for pdf in output_texts]\nprint(starting_index)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8fyN8SqlRZY","outputId":"0e3ea826-9dcd-49f8-ad88-2ae7ef14031f","execution":{"iopub.status.busy":"2024-01-10T15:45:47.440765Z","iopub.execute_input":"2024-01-10T15:45:47.441603Z","iopub.status.idle":"2024-01-10T15:45:47.447251Z","shell.execute_reply.started":"2024-01-10T15:45:47.441566Z","shell.execute_reply":"2024-01-10T15:45:47.446094Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":"[2922, 54, 94, 103, 85]\n"}]},{"cell_type":"code","source":"for i,starting_point in enumerate(starting_index):\n    print(output_texts[i][starting_point:starting_point+100])\n    print(\"\\n\\n\\n\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iiNlbrqJlRZZ","outputId":"3f4a518d-370e-4f79-c8c3-cea6b7dd6942","execution":{"iopub.status.busy":"2024-01-10T15:45:47.448608Z","iopub.execute_input":"2024-01-10T15:45:47.448963Z","iopub.status.idle":"2024-01-10T15:45:47.460662Z","shell.execute_reply.started":"2024-01-10T15:45:47.448929Z","shell.execute_reply":"2024-01-10T15:45:47.459710Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"ONE\n\nI ACCIDENTALLY VAPORIZE MY PRE-ALGEBRA\n\nTEACHER\n\nL\n\nook, I didn’t want to be a half-blood.\n\nIf you’r\n\n\n\n\n\n\n\n\n\nONE\n\n\t\n\nMY\tBEST\tFRIEND\tSHOPS\n\nFOR\tA\tWEDDING\tDRESS\n\nMy\tnightmare\tstarted\tlike\tthis.\n\nI\twas\tstanding\ton\ta\td\n\n\n\n\n\n\n\n\n\nONE  \n\nMY RESCUE OPERATION GOES VERY WRONG  \n\n  \n\nThe Friday before winter break, my mom packed me an o\n\n\n\n\n\n\n\n\n\nONE  \n\n \n\nI BATTLE THE \n\nCHEERLEADING SQUAD \n\n \n\nThe last thing I wanted to do on my summer break wa s bl\n\n\n\n\n\n\n\n\n\nONE \n\n \n\nI  GO  CRUISING  WITH \n\nEXPLOSIVES \n\n \n\nThe end of the world started when a pegasus landed on th\n\n\n\n\n\n\n\n\n"}]},{"cell_type":"markdown","source":"> We see that there are instances of additional spaces and tabs and thus this can lead to some discrepancies in the final output\n\n> The **endpoints** also need to be identified as there are other additional things found at the end of novels, like previews to other books or acknowledgments etc","metadata":{"id":"-palwhfVlRZZ"}},{"cell_type":"code","source":"print(output_texts[0][-10:-1])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hxlx2W-BlRZZ","outputId":"80531210-18c9-4afe-9a28-bf8804ee34b6","execution":{"iopub.status.busy":"2024-01-10T15:45:47.461905Z","iopub.execute_input":"2024-01-10T15:45:47.462933Z","iopub.status.idle":"2024-01-10T15:45:47.474324Z","shell.execute_reply.started":"2024-01-10T15:45:47.462906Z","shell.execute_reply":"2024-01-10T15:45:47.473412Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"com.\n\n\n\n\n\n\n\n\n\n\n"}]},{"cell_type":"code","source":"print(output_texts[1][-75:-1])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6u-IawOClRZZ","outputId":"44592605-77a7-488f-fdc6-86f09a1cdbc1","execution":{"iopub.status.busy":"2024-01-10T15:45:47.475591Z","iopub.execute_input":"2024-01-10T15:45:47.476200Z","iopub.status.idle":"2024-01-10T15:45:47.487764Z","shell.execute_reply.started":"2024-01-10T15:45:47.476168Z","shell.execute_reply":"2024-01-10T15:45:47.486903Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"s.”\n\nTable\tof\tContents\n\nPercy\tJackson\t2\n\nThe\tSea\tMonsters\n\nby\n\nRick\tRiordan\n\nONE\n"}]},{"cell_type":"code","source":"print(output_texts[2][-3:])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AE7mfpkQlRZZ","outputId":"787394ae-ef9a-4559-8941-93b9a0f9d716","execution":{"iopub.status.busy":"2024-01-10T15:45:47.489170Z","iopub.execute_input":"2024-01-10T15:45:47.489469Z","iopub.status.idle":"2024-01-10T15:45:47.501667Z","shell.execute_reply.started":"2024-01-10T15:45:47.489444Z","shell.execute_reply":"2024-01-10T15:45:47.500718Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n \n\n\n"}]},{"cell_type":"code","source":"print(output_texts[3][-6:])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBhwlBNvlRZZ","outputId":"f764dfb7-277d-46f7-8d3f-b3bbabf969d1","execution":{"iopub.status.busy":"2024-01-10T15:45:47.505749Z","iopub.execute_input":"2024-01-10T15:45:47.506139Z","iopub.status.idle":"2024-01-10T15:45:47.514285Z","shell.execute_reply.started":"2024-01-10T15:45:47.506091Z","shell.execute_reply":"2024-01-10T15:45:47.513394Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"ut.” \n\n\n"}]},{"cell_type":"code","source":"ending_index = [0,0,0,0,0]\n\nending_index[0] = -6\nending_index[1] = -71\nending_index[2] = -2\nending_index[3] = -5\nending_index[4] = output_texts[-1].find(\"ACKNOWLEDGMENTS\")\n","metadata":{"id":"q_sSK8w_lRZZ","execution":{"iopub.status.busy":"2024-01-10T15:45:47.515615Z","iopub.execute_input":"2024-01-10T15:45:47.515905Z","iopub.status.idle":"2024-01-10T15:45:47.525868Z","shell.execute_reply.started":"2024-01-10T15:45:47.515879Z","shell.execute_reply":"2024-01-10T15:45:47.525066Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"> We now know the starting and ending points for all the books, and thus we **clip the list elements**","metadata":{"id":"s9p-GELSlRZa"}},{"cell_type":"code","source":"output_texts = [output_texts[i][starting_index[i]:ending_index[i]] for i in range(len(output_texts))]\n\ncombined = \"\\n\\n\\n\".join(output_texts)","metadata":{"id":"m7efFWN-lRZa","execution":{"iopub.status.busy":"2024-01-10T15:45:47.526874Z","iopub.execute_input":"2024-01-10T15:45:47.527167Z","iopub.status.idle":"2024-01-10T15:45:47.544306Z","shell.execute_reply.started":"2024-01-10T15:45:47.527142Z","shell.execute_reply":"2024-01-10T15:45:47.543393Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Checking if there any characters present only in the last book which aren't present in the others","metadata":{"id":"BxSvtWHClRZa"}},{"cell_type":"code","source":"firstfour = \"\\n\".join(output_texts[:-1])\nlast = output_texts[-1]\nprint(set(last)-set(firstfour))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4ljQifnlRZa","outputId":"1297677e-c629-4b2f-99be-0880ab938a6a","execution":{"iopub.status.busy":"2024-01-10T15:45:47.545699Z","iopub.execute_input":"2024-01-10T15:45:47.546089Z","iopub.status.idle":"2024-01-10T15:45:47.599732Z","shell.execute_reply.started":"2024-01-10T15:45:47.546053Z","shell.execute_reply":"2024-01-10T15:45:47.598668Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"{'τ', 'ε', 'Π', 'φ', 'ς', 'ι', 'Δ', 'ο', 'ή', 'η', 'κ', 'ρ', '~', 'ί', 'σ', 'Ω', 'υ', 'ύ'}\n"}]},{"cell_type":"code","source":"for i,text in enumerate(output_texts):\n    print(\"\\n\\n\\nBook\",i+1,\":\")\n    print(\"\\n\\nStart:\\n\")\n    print(text[:25])\n    print(\"\\n\\nEnd:\\n\")\n    print(text[-25:])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F6l4jceQlRZa","outputId":"b6d04744-fc1d-498b-d5d9-c20eedcc08d9","execution":{"iopub.status.busy":"2024-01-10T15:45:47.601174Z","iopub.execute_input":"2024-01-10T15:45:47.601993Z","iopub.status.idle":"2024-01-10T15:45:47.611018Z","shell.execute_reply.started":"2024-01-10T15:45:47.601957Z","shell.execute_reply":"2024-01-10T15:45:47.610160Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\n\n\n\nBook 1 :\n\n\n\n\n\nStart:\n\n\n\nONE\n\nI ACCIDENTALLY VAPORI\n\n\n\n\n\nEnd:\n\n\n\n at \n\nwww.rickriordan.com.\n\n\n\n\n\n\n\nBook 2 :\n\n\n\n\n\nStart:\n\n\n\nONE\n\n\t\n\nMY\tBEST\tFRIEND\tSHOP\n\n\n\n\n\nEnd:\n\n\n\naid.\t“Daughter\tof\tZeus.”\n\n\n\n\n\n\n\n\n\nBook 3 :\n\n\n\n\n\nStart:\n\n\n\nONE  \n\nMY RESCUE OPERATION\n\n\n\n\n\nEnd:\n\n\n\nid, ' I await you...'\"  \n\n\n\n\n\n\n\n\n\nBook 4 :\n\n\n\n\n\nStart:\n\n\n\nONE  \n\n \n\nI BATTLE THE \n\nCHE\n\n\n\n\n\nEnd:\n\n\n\ne \n\ngot a lot to talk abou\n\n\n\n\n\n\n\nBook 5 :\n\n\n\n\n\nStart:\n\n\n\nONE \n\n \n\nI  GO  CRUISING  W\n\n\n\n\n\nEnd:\n\n\n\n I didn't look back. \n\n \n\n \n"}]},{"cell_type":"markdown","source":"# 4. Encoding Text\n\nThis is a character level text generation system, thus Label Encoding is sufficient, and Embedding is the next step\n\nThe first step would be to identify all the unique characters and then build functions to encode and decode the text","metadata":{"id":"KKs95kbNlRZa"}},{"cell_type":"code","source":"chars = sorted(list(set(combined)))\nvocab_size = len(chars)\nprint(\"Total number of unique characters:\",vocab_size)\nstoi = { ch:i for i,ch in enumerate(chars) }\nitos = { i:ch for i,ch in enumerate(chars) }\nencode = lambda s: [stoi[c] for c in s]\ndecode = lambda l: ''.join([itos[i] for i in l])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Bj-VLnKlRZa","outputId":"bcb648f4-b1e5-44ed-cf8c-dd69a7c28575","execution":{"iopub.status.busy":"2024-01-10T15:45:47.612256Z","iopub.execute_input":"2024-01-10T15:45:47.612621Z","iopub.status.idle":"2024-01-10T15:45:47.659850Z","shell.execute_reply.started":"2024-01-10T15:45:47.612589Z","shell.execute_reply":"2024-01-10T15:45:47.658735Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"Total number of unique characters: 117\n"}]},{"cell_type":"code","source":"print(\"This is a list of all the tokens and the characters they represent\")\nfor i,token in enumerate(chars):\n    print(i,\":\",token,\"<>\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wnbDk_7qlRZa","outputId":"0082083a-748e-4dad-f68b-c23609432c59","execution":{"iopub.status.busy":"2024-01-10T15:45:47.661513Z","iopub.execute_input":"2024-01-10T15:45:47.661841Z","iopub.status.idle":"2024-01-10T15:45:47.674056Z","shell.execute_reply.started":"2024-01-10T15:45:47.661811Z","shell.execute_reply":"2024-01-10T15:45:47.673274Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":"This is a list of all the tokens and the characters they represent\n\n0 : \t <>\n\n1 : \n\n <>\n\n2 :   <>\n\n3 : ! <>\n\n4 : \" <>\n\n5 : # <>\n\n6 : $ <>\n\n7 : & <>\n\n8 : ' <>\n\n9 : ( <>\n\n10 : ) <>\n\n11 : * <>\n\n12 : + <>\n\n13 : , <>\n\n14 : - <>\n\n15 : . <>\n\n16 : / <>\n\n17 : 0 <>\n\n18 : 1 <>\n\n19 : 2 <>\n\n20 : 3 <>\n\n21 : 4 <>\n\n22 : 5 <>\n\n23 : 6 <>\n\n24 : 7 <>\n\n25 : 8 <>\n\n26 : 9 <>\n\n27 : : <>\n\n28 : ; <>\n\n29 : ? <>\n\n30 : A <>\n\n31 : B <>\n\n32 : C <>\n\n33 : D <>\n\n34 : E <>\n\n35 : F <>\n\n36 : G <>\n\n37 : H <>\n\n38 : I <>\n\n39 : J <>\n\n40 : K <>\n\n41 : L <>\n\n42 : M <>\n\n43 : N <>\n\n44 : O <>\n\n45 : P <>\n\n46 : Q <>\n\n47 : R <>\n\n48 : S <>\n\n49 : T <>\n\n50 : U <>\n\n51 : V <>\n\n52 : W <>\n\n53 : X <>\n\n54 : Y <>\n\n55 : Z <>\n\n56 : a <>\n\n57 : b <>\n\n58 : c <>\n\n59 : d <>\n\n60 : e <>\n\n61 : f <>\n\n62 : g <>\n\n63 : h <>\n\n64 : i <>\n\n65 : j <>\n\n66 : k <>\n\n67 : l <>\n\n68 : m <>\n\n69 : n <>\n\n70 : o <>\n\n71 : p <>\n\n72 : q <>\n\n73 : r <>\n\n74 : s <>\n\n75 : t <>\n\n76 : u <>\n\n77 : v <>\n\n78 : w <>\n\n79 : x <>\n\n80 : y <>\n\n81 : z <>\n\n82 : ~ <>\n\n83 : ° <>\n\n84 : Ô <>\n\n85 : á <>\n\n86 : é <>\n\n87 : ê <>\n\n88 : ë <>\n\n89 : ï <>\n\n90 : ñ <>\n\n91 : Ȇ <>\n\n92 : Δ <>\n\n93 : Π <>\n\n94 : ή <>\n\n95 : ί <>\n\n96 : ε <>\n\n97 : η <>\n\n98 : ι <>\n\n99 : κ <>\n\n100 : ο <>\n\n101 : ρ <>\n\n102 : ς <>\n\n103 : σ <>\n\n104 : τ <>\n\n105 : υ <>\n\n106 : φ <>\n\n107 : ύ <>\n\n108 : – <>\n\n109 : — <>\n\n110 : ‘ <>\n\n111 : ’ <>\n\n112 : “ <>\n\n113 : ” <>\n\n114 : … <>\n\n115 : Ω <>\n\n116 : ∆ <>\n"}]},{"cell_type":"code","source":"encoded_texts = [torch.tensor(encode(text), dtype=torch.long) for text in output_texts]\n\nfor text in encoded_texts:\n    print(text[:50])\n    print(type(text))\n    print(text.shape)\n    print(\"\\n\\n\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFofunoZlRZa","outputId":"7f065683-b280-49c9-c0ea-03f3c4733715","execution":{"iopub.status.busy":"2024-01-10T15:45:47.675208Z","iopub.execute_input":"2024-01-10T15:45:47.675566Z","iopub.status.idle":"2024-01-10T15:45:48.240975Z","shell.execute_reply.started":"2024-01-10T15:45:47.675517Z","shell.execute_reply":"2024-01-10T15:45:48.240035Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([44, 43, 34,  1, 38,  2, 30, 32, 32, 38, 33, 34, 43, 49, 30, 41, 41, 54,\n\n         2, 51, 30, 45, 44, 47, 38, 55, 34,  2, 42, 54,  2, 45, 47, 34, 14, 30,\n\n        41, 36, 34, 31, 47, 30,  1, 49, 34, 30, 32, 37, 34, 47])\n\n<class 'torch.Tensor'>\n\ntorch.Size([502990])\n\n\n\n\n\n\n\ntensor([44, 43, 34,  1,  0,  1, 42, 54,  0, 31, 34, 48, 49,  0, 35, 47, 38, 34,\n\n        43, 33,  0, 48, 37, 44, 45, 48,  1, 35, 44, 47,  0, 30,  0, 52, 34, 33,\n\n        33, 38, 43, 36,  0, 33, 47, 34, 48, 48,  1, 42, 80,  0])\n\n<class 'torch.Tensor'>\n\ntorch.Size([359216])\n\n\n\n\n\n\n\ntensor([44, 43, 34,  2,  2,  1, 42, 54,  2, 47, 34, 48, 32, 50, 34,  2, 44, 45,\n\n        34, 47, 30, 49, 38, 44, 43,  2, 36, 44, 34, 48,  2, 51, 34, 47, 54,  2,\n\n        52, 47, 44, 43, 36,  2,  2,  1,  2,  2,  1, 49, 63, 60])\n\n<class 'torch.Tensor'>\n\ntorch.Size([410240])\n\n\n\n\n\n\n\ntensor([44, 43, 34,  2,  2,  1,  2,  1, 38,  2, 31, 30, 49, 49, 41, 34,  2, 49,\n\n        37, 34,  2,  1, 32, 37, 34, 34, 47, 41, 34, 30, 33, 38, 43, 36,  2, 48,\n\n        46, 50, 30, 33,  2,  1,  2,  1, 49, 63, 60,  2, 67, 56])\n\n<class 'torch.Tensor'>\n\ntorch.Size([484911])\n\n\n\n\n\n\n\ntensor([44, 43, 34,  2,  1,  2,  1, 38,  2,  2, 36, 44,  2,  2, 32, 47, 50, 38,\n\n        48, 38, 43, 36,  2,  2, 52, 38, 49, 37,  2,  1, 34, 53, 45, 41, 44, 48,\n\n        38, 51, 34, 48,  2,  1,  2,  1, 49, 63, 60,  2, 60, 69])\n\n<class 'torch.Tensor'>\n\ntorch.Size([506631])\n\n\n\n\n\n\n"}]},{"cell_type":"markdown","source":"We now have a list of tensors, we cannot stack them together as they are of diferent lengths and padding can lead to complications in obtaining batches","metadata":{"id":"ca-gE3Z7lRZa"}},{"cell_type":"markdown","source":"# 5. Obtaining batches","metadata":{"id":"UDdvoK-MlRZb"}},{"cell_type":"markdown","source":"- There is a need to **evenly obtain the samples from all the books**, and thus determine the samples to be taken per tensor\n- ix provides a random list of starting indices per tensor, ensuring that the entire block_size of context can be obtained (no out of bounds error)\n- A tensor of shape **(samples_per_tensor, block_size)** is appended to x_tensors and y_tensors per book\n- x and y are the concaternated form of x_tensors and y-tensors, and their shape is **(batch_size,block_size)**","metadata":{"id":"8JXu12IvlRZb"}},{"cell_type":"code","source":"print(len(encoded_texts[-1].view(1,-1)))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omMkp5yNlRZb","outputId":"df9144f7-820e-4d32-d7ad-a92daa5cc273","execution":{"iopub.status.busy":"2024-01-10T15:45:48.242314Z","iopub.execute_input":"2024-01-10T15:45:48.242694Z","iopub.status.idle":"2024-01-10T15:45:48.247964Z","shell.execute_reply.started":"2024-01-10T15:45:48.242664Z","shell.execute_reply":"2024-01-10T15:45:48.247153Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":"1\n"}]},{"cell_type":"markdown","source":"Final book is used for testing, all others are used for training","metadata":{"id":"U25Ei5F0lRZc"}},{"cell_type":"code","source":"def get_batch(func):\n    sample =\"\"\n    if func == 'train':\n        sample = encoded_texts[:-1]\n    elif func == 'val':\n        sample = encoded_texts[-1].view(1,-1)\n    samples_per_tensor = batch_size //len(sample)\n    x_tensors, y_tensors = [], []\n    for tensor in sample:\n        ix = torch.randint(len(tensor) - block_size, (samples_per_tensor,))\n        #print(\"idx:\",len(ix))\n        x_tensors.append(torch.stack([tensor[i:i+block_size] for i in ix]))\n        y_tensors.append(torch.stack([tensor[i+1:i+block_size+1] for i in ix]))\n        #print(\"x:\",len(x_tensors),x_tensors[-1].shape,\"\\n\\n\")\n\n    x = torch.cat(x_tensors, dim=0)\n    y = torch.cat(y_tensors, dim=0)\n\n    x, y = x.to(device), y.to(device)\n    return x, y\n","metadata":{"id":"5e3DGHFalRZc","execution":{"iopub.status.busy":"2024-01-10T15:45:48.249137Z","iopub.execute_input":"2024-01-10T15:45:48.249493Z","iopub.status.idle":"2024-01-10T15:45:48.259504Z","shell.execute_reply.started":"2024-01-10T15:45:48.249436Z","shell.execute_reply":"2024-01-10T15:45:48.258436Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# 6. Implementing a HEAD of Self-Attention\n\n<div style=\"text-align:center\">\n    <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*piCQbDMPO1-Kw5ZiNAl-FA.png\" alt=\"Image\" style=\"width:500px;height:300px;\"/>\n    <br>\n    <a href=\"https://medium.com/@saba99/self-attention-0b21baad0a48\" style=\"font-size: smaller;\" > <b>Source</b> </a>\n\n</div>\n\n- The transformer model utilises parallelism and calculates 3 metrics:\n    - *Query*: What the current point is looking for\n    - *Key*: What the current point can offer\n    - *Value*: The value of the current point<br>\n<br>\n- For all tokens to be generated (max_new_tokens) the QKVs are calculated and stored in a 3 individual tensors\n- Now the **affinity** of current token's query needs to be calculated with all other output_tokens' keys, and this is calculated simply using the **dot product** (done via matrix multiplication with transpose)\n- Since this is a decoder only transformer, the self attention model will consider key and values from all **previous tokens** to generate current output, and not the tokens to be generated in the future\n- A **lower traingular matrix** is used discard all future tokens\n- The dot product reveal the weights given to the values of all tokens, This needs to be **scaled down** to prevent extremities that might occur when doing softmax\n    - eg - softmaxing 5 and 50 vs softmaxing 0.5 and 5\n- the scaled weights need to **softmaxed** to be scaled between 0 and 1\n- The **attention scores** have thus been obtained\n- Thus the ouput will be the **weighted average** of all previous tokens' values in the block_size\n- This is done for all tokens\n","metadata":{"id":"PEwmPI9elRZc"}},{"cell_type":"code","source":"class Head(nn.Module):\n\n    def __init__(self, head_size):\n        super().__init__()\n\n        self.key = nn.Sequential(\n            nn.Linear(n_embd, head_size // 2),\n            nn.Tanh(),\n            nn.Linear(head_size // 2, head_size, bias=False)\n        )\n        self.query = nn.Sequential(\n            nn.Linear(n_embd, head_size // 2),\n            nn.Tanh(),\n            nn.Linear(head_size // 2, head_size, bias=False)\n        )\n        self.value = nn.Sequential(\n            nn.Linear(n_embd, head_size // 2),\n            nn.Tanh(),\n            nn.Linear(head_size // 2, head_size, bias=False)\n        )\n\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n\n        Ba,Bl,C = x.shape # x has shape (batch_size, block_size, n_embd)\n        k = self.key(x)   # k has shape (batch_size, block_size, head_size)\n        q = self.query(x) # q has shape (batch_size, block_size, head_size)\n        aff = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (Ba, Bl, hs) @ (Ba, hs, Bl) -> (Ba, Bl, Bl)\n        aff = aff.masked_fill(self.tril[:Bl, :Bl] == 0, float('-inf')) # (Ba, Bl, Bl)\n        aff = F.softmax(aff, dim=-1) # (Ba, Bl, Bl)\n        aff = self.dropout(aff)\n        # perform the weighted aggregation of the values\n        v = self.value(x) # (Ba,Bl,head_size)\n        att_out = aff @ v # (Ba, Bl, Bl) @ (Ba, Bl, head_size) -> (Ba, Bl, head_size)\n        return att_out\n","metadata":{"id":"dTrYBF53lRZc","execution":{"iopub.status.busy":"2024-01-10T15:45:48.260892Z","iopub.execute_input":"2024-01-10T15:45:48.261271Z","iopub.status.idle":"2024-01-10T15:45:48.273929Z","shell.execute_reply.started":"2024-01-10T15:45:48.261236Z","shell.execute_reply":"2024-01-10T15:45:48.272823Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# 7. Implementing Multi-head Attention\n\n<div style=\"text-align:center\">\n    <img src=\"https://production-media.paperswithcode.com/methods/multi-head-attention_l1A3G7a.png\" alt=\"Image\" style=\"width:300px;height:400px;\"/>\n    <br>\n    <a href=\"https://paperswithcode.com/method/multi-head-attention\" style=\"font-size: smaller;\" > <b>Source</b> </a>\n\n</div>\n\n- To further improve the accuracy, multiple heads of self attention can be employed in **parallel**\n- The paper \"Attention is all you need\" used 8 heads of attention\n- The outputs of all the heads are concatenated together\n<br><br>\n- The self.heads retrieves num_heads individual Head instances, which are processed in PARALLEL, not Sequentitally\n- In the forward pass, each of these heads produces an output of shape **(batch_size,block_size,head_size)**\n- These are concatenated in the -1 dimension, so the output is **(batch_size,block_size,head_size * num_heads)**\n- This is where the self.proj is used to transform the output to **(batch_size,block_size,n_embd)**","metadata":{"id":"JI9cT6FhlRZc"}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for cur_head in range(num_heads)])\n        self.proj = nn.Sequential(\n            nn.Linear(head_size * num_heads, n_embd//2),\n            nn.Tanh(),\n            nn.Linear(n_embd//2, n_embd)\n        )\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([head(x) for head in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out","metadata":{"id":"VjKc_7yElRZc","execution":{"iopub.status.busy":"2024-01-10T15:45:48.275291Z","iopub.execute_input":"2024-01-10T15:45:48.276180Z","iopub.status.idle":"2024-01-10T15:45:48.288352Z","shell.execute_reply.started":"2024-01-10T15:45:48.276146Z","shell.execute_reply":"2024-01-10T15:45:48.287606Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# 8. FeedForward and Layer Normalisation for Residual Connection in a Block\n\n<div style=\"text-align:center\">\n    <img src=\"https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-17.png\" alt=\"Image\" style=\"width:300px;height:400px;\"/>\n    <br>\n    <a href=\"https://builtin.com/artificial-intelligence/transformer-neural-network\" style=\"font-size: smaller;\" > <b>Source</b> </a>\n\n</div>\n\n- The x value (post position embedding) is **saved** and used as input to calculate the **self-attention (weighted average) tensor** for each token, after **normalisation**\n- The original x is **added** to this self-attention value, using a **residual connection**, resulting in the updated value of x\n- The new updated x is also **saved**, **normalised** and passed to the **Feed Forward network**, to improve on the **non-linearity**\n- Using a **residual connection**, and is this is **added** to the new updated x\n- LayerNorm is a Layer Normalisation layer, it doesn't have trainabale weights, but it does have learnable parameters (**gamma** and **beta**)","metadata":{"id":"pp6KaEQIlRZd"}},{"cell_type":"code","source":"class FeedForward(nn.Module):\n\n    def __init__(self, n_embd):\n        super().__init__()\n        self.nonlin = nn.Sequential(\n            nn.Linear(n_embd, 6 * n_embd),\n            nn.Tanh(),\n            nn.Linear(6 * n_embd, n_embd),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.nonlin(x)\n","metadata":{"id":"W4-CcbMelRZd","execution":{"iopub.status.busy":"2024-01-10T15:45:48.289342Z","iopub.execute_input":"2024-01-10T15:45:48.289684Z","iopub.status.idle":"2024-01-10T15:45:48.303219Z","shell.execute_reply.started":"2024-01-10T15:45:48.289655Z","shell.execute_reply":"2024-01-10T15:45:48.302489Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n\n    def __init__(self, n_embd, n_head):\n        super().__init__()\n        head_size = n_embd // n_head\n        self.attention = MultiHeadAttention(n_head, head_size)\n        self.ffd = FeedForward(n_embd)\n        self.norm1 = nn.LayerNorm(n_embd)\n        self.norm2 = nn.LayerNorm(n_embd)\n\n    def forward(self, x):\n        new_updated_x = x + self.attention(self.norm1(x))\n        final_x = new_updated_x + self.ffd(self.norm2(new_updated_x))\n        return final_x\n","metadata":{"id":"j2aMrSK6lRZl","execution":{"iopub.status.busy":"2024-01-10T15:45:48.304258Z","iopub.execute_input":"2024-01-10T15:45:48.304548Z","iopub.status.idle":"2024-01-10T15:45:48.314357Z","shell.execute_reply.started":"2024-01-10T15:45:48.304516Z","shell.execute_reply":"2024-01-10T15:45:48.313510Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# 9. Pre-Block Creation\n\n<div style=\"text-align:center\">\n    <img src=\"https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-21.png\" alt=\"Image\" style=\"width:150px;height:400px;\"/>\n    <br>\n    <a href=\"https://builtin.com/artificial-intelligence/transformer-neural-network\" style=\"font-size: smaller;\" > <b>Source</b> </a>\n\n</div>\n\n- When the input character is received, it'll have been **Label Encoded**\n- This needs to be converted:\n    - One-Hot-Vector is not enough as it fails to identify the relations between words\n    - Thus an **embedding vector** is needed\n- The position occupied by the idx is also important as it helps understand **long range dependencies**, as well as intricate inherent **word ordering** present in the novels","metadata":{"id":"lN6wcL5OlRZl"}},{"cell_type":"code","source":"def long_tanh(x):\n    return x.tanh().long()","metadata":{"id":"m-N0YoRIlRZm","execution":{"iopub.status.busy":"2024-01-10T15:45:48.315711Z","iopub.execute_input":"2024-01-10T15:45:48.316046Z","iopub.status.idle":"2024-01-10T15:45:48.325810Z","shell.execute_reply.started":"2024-01-10T15:45:48.316020Z","shell.execute_reply":"2024-01-10T15:45:48.324890Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class PreBlock(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n\n#         self.emb1 = nn.Embedding (vocab_size, n_embd//2)\n#         self.emb2 = nn.Embedding (n_embd//2, n_embd)\n\n#         self.pos1 = nn.Embedding (vocab_size, n_embd//2)\n#         self.pos2 = nn.Embedding (n_embd//2, n_embd)\n\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n\n\n#         self.token_embedding_table = nn.Sequential(\n#                                         nn.Embedding(vocab_size, n_embd // 2),\n#                                         nn.Tanh(),\n#                                         nn.Embedding( n_embd // 2, n_embd )\n#                                     )\n\n\n\n#         self.position_embedding_table = nn.Sequential(\n#                                             nn.Embedding(vocab_size, n_embd // 2),\n#                                             nn.Tanh(),\n#                                             nn.Embedding( n_embd // 2, n_embd )\n#                                         )\n\n\n\n    def forward(self, idx):\n        B, T = idx.shape\n\n#         tok_emb = self.emb1(idx)\n#         tok_emb = torch.tanh(tok_emb)\n#         tok_emb = tok_emb.long()\n#         tok_emb = self.emb2(tok_emb)\n\n        tok_emb = self.token_embedding_table(idx)\n\n        pos_emb = self.position_embedding_table(torch.arange(T, device=idx.device))  # 2D, no Batch dim\n        #print(tok_emb.shape,\"\\n\",pos_emb.shape)\n        pos_emb = pos_emb.expand_as(tok_emb)  # 3D\n\n\n        embedded_output = tok_emb + pos_emb  # 3D\n        return embedded_output","metadata":{"id":"JandGLkllRZm","execution":{"iopub.status.busy":"2024-01-10T15:45:48.326997Z","iopub.execute_input":"2024-01-10T15:45:48.327263Z","iopub.status.idle":"2024-01-10T15:45:48.338588Z","shell.execute_reply.started":"2024-01-10T15:45:48.327240Z","shell.execute_reply":"2024-01-10T15:45:48.337649Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# 10. Post-Block Creation\n\n<div style=\"text-align:center\">\n    <img src=\"https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-25.png\" alt=\"Image\" style=\"width:150px;height:400px;\"/>\n    <br>\n    <a href=\"https://builtin.com/artificial-intelligence/transformer-neural-network\" style=\"font-size: smaller;\" > <b>Source</b> </a>\n\n</div>\n\n- The output froom the blocks needs to be normalised to promote better distribution of probabilities\n- Following this, a softmax layer is used to convert the **(batch_size, block_size, n_embd)** to **(batch_size, block_size, vocab_size)**\n","metadata":{"id":"3fEkgP3xlRZm"}},{"cell_type":"code","source":"class PostBlock(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.fin_norm = nn.LayerNorm(n_embd)\n        self.soft_score = nn.Sequential(\n                           nn.Linear(n_embd, vocab_size // 2),\n                           nn.Tanh(),\n                           nn.Linear( vocab_size // 2, vocab_size )\n                        )\n    def forward(self, x):\n        x = self.fin_norm(x)\n        logits = self.soft_score(x)\n        return logits","metadata":{"id":"K0TqRs1PlRZn","execution":{"iopub.status.busy":"2024-01-10T15:45:48.339940Z","iopub.execute_input":"2024-01-10T15:45:48.340273Z","iopub.status.idle":"2024-01-10T15:45:48.353417Z","shell.execute_reply.started":"2024-01-10T15:45:48.340245Z","shell.execute_reply":"2024-01-10T15:45:48.352635Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# 11. Putting it all together (Transformer)\n\n- This section will combine the previous sections to make the transformer class\n- The 3 sections are:\n    - Pre-Block\n    - Block\n    - Post-Block\n\n- Following this a **cross entropy loss** will be used to assess loss and perform **back propagration**","metadata":{"id":"3cLO7KiilRZn"}},{"cell_type":"code","source":"class Transformer(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.pre_block = PreBlock()\n        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n        self.post_block = PostBlock()\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, idx, targets=None):\n\n        x = self.pre_block(idx)\n        x = self.blocks(x)\n        logits = self.post_block(x)\n\n        if targets is None:\n            loss = None\n        else:\n            batch, block, vocab = logits.shape\n            logits = logits.view(batch*block, vocab)\n            targets = targets.view(batch*block)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        for _ in range(max_new_tokens):\n            idx_cond = idx[:, -block_size:] #look at the text generated so far and sonly consider the context window\n\n            logits, loss = self(idx_cond) # get the predictions\n\n            logits = logits[:, -1, :] # considering the loss for the probabilities for the last token's upcoming token\n            #its shape is now (batch_size, vocab_size)\n\n            probs = F.softmax(logits, dim=-1) # apply softmax to get probabilities\n\n            idx_next = torch.multinomial(probs, num_samples=1) # get next token, shape is (batch_size, 1)\n\n            idx = torch.cat((idx, idx_next), dim=1) # append sampled index to the running sequence,idx shape is now (batch_size, block_size+1)\n        return idx","metadata":{"id":"N4_tkPhjlRZn","execution":{"iopub.status.busy":"2024-01-10T15:45:48.354478Z","iopub.execute_input":"2024-01-10T15:45:48.356595Z","iopub.status.idle":"2024-01-10T15:45:48.370335Z","shell.execute_reply.started":"2024-01-10T15:45:48.356565Z","shell.execute_reply":"2024-01-10T15:45:48.369292Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# 12. Instantiation and Model Training","metadata":{"id":"VZ4nbvm8lRZn"}},{"cell_type":"code","source":"model = Transformer()\nm = model.to(device) #Utilise GPU if available\n\nprint(sum(p.numel() for p in m.parameters())/1e6, 'M parameters',end = \"\\n\\n\\n\")\n\n#print(torchsummary.summary(model, input_size=(batch_size, block_size)),end = \"\\n\\n\\n\")\n\n#for name, param in model.named_parameters():\n#    print(name, param.shape)\n\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xG04AeJ1lRZo","outputId":"8f8af8b4-6e75-4de1-dd8c-b4eb596a8407","execution":{"iopub.status.busy":"2024-01-10T15:45:48.376364Z","iopub.execute_input":"2024-01-10T15:45:48.376734Z","iopub.status.idle":"2024-01-10T15:45:49.035216Z","shell.execute_reply.started":"2024-01-10T15:45:48.376709Z","shell.execute_reply":"2024-01-10T15:45:49.034216Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":"15.691057 M parameters\n\n\n\n\n"}]},{"cell_type":"markdown","source":"- Making a Visual estimator of loss\n- A specific train and test test hasn't been separated from the original dataset\n- So the final book is used as a test and first 4 books are used for training","metadata":{"id":"a01SNWpflRZo"}},{"cell_type":"code","source":"def estimate_loss():\n    out = {}\n    model.eval()\n    for state in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch(state)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[state] = losses.mean()\n    model.train()\n    return out","metadata":{"id":"NI-nsQNulRZo","execution":{"iopub.status.busy":"2024-01-10T15:45:49.036452Z","iopub.execute_input":"2024-01-10T15:45:49.036762Z","iopub.status.idle":"2024-01-10T15:45:49.043432Z","shell.execute_reply.started":"2024-01-10T15:45:49.036737Z","shell.execute_reply":"2024-01-10T15:45:49.042228Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Training Loop","metadata":{"id":"jKaQabVYlRZp"}},{"cell_type":"code","source":"# for iter in range(max_iters):\n\n#     # every once in a while evaluate the loss on train and val sets\n#     if iter % eval_interval == 0 or iter == max_iters - 1:\n#         losses = estimate_loss()\n#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n#     # sample a batch of data\n#     xb, yb = get_batch('train')\n\n#     # evaluate the loss\n#     logits, loss = model(xb, yb)\n#     optimizer.zero_grad(set_to_none=True)\n#     loss.backward()\n#     optimizer.step()\n\nbest_val_loss = float('inf')  # Initialize best validation loss\npatience = 3  # Number of epochs to wait for improvement\nepochs_since_improvement = 0  # Track number of epochs without improvement\n\nalternate = False\n\nfor iter in range(max_iters):\n\n    # Evaluate loss every eval_interval iterations or at the end\n    if iter % eval_interval == 0 or iter == max_iters - 1:\n        losses = estimate_loss()\n        print(f\"\\n\\nstep {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\\n\")\n        if(bool):\n            context = torch.zeros((1, 1), dtype=torch.long, device=device)\n            print(decode(m.generate(context, max_new_tokens=100)[0].tolist()))\n\n        alternate = !alternate\n\n        # Early stopping based on validation loss\n        if losses['val'] < best_val_loss:\n            best_val_loss = losses['val']\n            epochs_since_improvement = 0  # Reset counter if validation loss improves\n        else:\n            epochs_since_improvement += 1\n\n        if epochs_since_improvement >= patience:\n            print(\"Early stopping triggered!\")\n            break  # Exit the loop\n\n    # Training steps (unchanged)\n    xb, yb = get_batch('train')\n    logits, loss = model(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kdc--mgHlRZp","outputId":"fdd83675-50b0-4e7d-c7ca-38eaf47b7e76","execution":{"iopub.status.busy":"2024-01-10T15:45:49.044679Z","iopub.execute_input":"2024-01-10T15:45:49.044976Z","iopub.status.idle":"2024-01-10T20:07:58.171124Z","shell.execute_reply.started":"2024-01-10T15:45:49.044950Z","shell.execute_reply":"2024-01-10T20:07:58.170028Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\n\nstep 0: train loss 4.7578, val loss 4.7563\n\n\n\n\t#ZJZV0”rήh,ύHëD;Ôυbx/+T0…W-\"ίηUJUi*y:FΩDig7m“WBr‘k'YF,B0;cñο–°rMD∆ιPsMv\"Ω\t*GΠêñr6~AΔÔPrUb’“L0yτ”ςqςφ\n\n\n\n\n\nstep 1000: train loss 2.2225, val loss 2.2400\n\n\n\n\tked\the\thyou\tdold\tadr6Vis,dnngh\todea Annns\tsral\ttoar Gldre..\tςas\tI\twhe\tulυ\ttrurncke\tpnotht’s\tto\ton$ï \n\n\n\n\n\nstep 2000: train loss 1.4958, val loss 1.5560\n\n\n\n\twas\twabord\tacrossing\tabou commment.\tBut\tsubblyed\tnow\tthe\ttornïd\tmolion\tthe\tdoorn\twhiole\tήise\twill, w\n\n\n\n\n\nstep 3000: train loss 1.2847, val loss 1.3889\n\n\n\n\tbullsider\tcall\tthe\tcentaure\twofinal.\tIf\tmy\tthought\tsto\twould\tbe\tto\tthis\n\nhippocampus\tof\tkind\tof\tsmile\n\n\n\n\n\nstep 4000: train loss 1.1734, val loss 1.3297\n\n\n\n\twheere\tin\n\nhead,\tthe\tthough\tit\twas\twe\tdazed\twith\thit\tinsidiffeed\tof\tthe\tmenaother\tcamper\tof\tthe\tdayti\n\n\n\n\n\nstep 5000: train loss 1.0891, val loss 1.2981\n\n\n\n\tvoice\tthe\tdistancidely,\thigh\tCyclops\twere\teyes.\n\nGrover\tran\tour\tface\tstill.\tThe\tbearbal\tthat\tthoughts\n\n\n\n\n\nstep 6000: train loss 1.0176, val loss 1.2936\n\n\n\n\tguard\tand\tSloan\tsbelly\ttrainer.\tThe\tbelly\twas\ta\tgiant\tmall!\tZeus’s\tharmoos\toverr\n\nI\ttooking.\tEven\tI\ts\n\n\n\n\n\nstep 7000: train loss 0.9514, val loss 1.2952\n\n\n\n\tbig\t\n\nsailor!”\tThe\tvoice\tsaid.\t“I\tguests\tmoney\tout\tof\tthis\tmonster\talls\tand\tsaty\n\nintented\twhen\tyou,\tS\n\n\n\n\n\nstep 8000: train loss 0.8870, val loss 1.3061\n\n\n\n\tWhat\thadn’t\tbeen\tlikeft.\n\nThere\twas\ta\tdughteical\tbut\tfifty\tfeet\taway.\tOnce\twe’d\tever\tback\tto\tcamp\n\ntha\n\n\n\n\n\nstep 9000: train loss 0.8266, val loss 1.3263\n\n\n\n\tstill\tship\twith\tAnnabeth\talowfuled,\t“Helen?”\tand\tthe\tmonster\tboth\n\nsnared\tand\twaved\ta\tclaw\tand\tripped\n\nEarly stopping triggered!\n"}]},{"cell_type":"markdown","source":"### Sample Generation","metadata":{"id":"Ny1QYUxMGLHj"}},{"cell_type":"code","source":"# context = torch.zeros((1, 1), dtype=torch.long, device=device)\n\ncontext = torch.tensor([[36]], dtype=torch.long, device=device)\nprint(decode(m.generate(context, max_new_tokens=50)[0].tolist()))\n","metadata":{"id":"_14OTRcNlRZp","execution":{"iopub.status.busy":"2024-01-10T20:15:57.458927Z","iopub.execute_input":"2024-01-10T20:15:57.459770Z","iopub.status.idle":"2024-01-10T20:16:03.937543Z","shell.execute_reply.started":"2024-01-10T20:15:57.459736Z","shell.execute_reply":"2024-01-10T20:16:03.936530Z"},"outputId":"87f968bd-e4bf-4600-d49f-91e5820d2942","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":"Grover.\n\nI didn’t understand when I returned to ripp\n"}]},{"cell_type":"markdown","source":"# 13. Saving, Calculating Size and Loading Models Weights","metadata":{"id":"nm3-2JtNGLHj"}},{"cell_type":"code","source":"#saving weights\ntorch.save(model.state_dict(), 'TransformerModel.pth')\n\n\nfiles.download('TransformerModel.pth')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"LaZqGmBT81Ue","outputId":"72b4cfef-e23e-4e52-b937-7b7da26217a6"},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_de0423f5-1a2d-4e60-b635-34d202a1f082\", \"TransformerModel.pth\", 130162334)"]},"metadata":{}}]},{"cell_type":"code","source":"#calculating size\nprint(\"The size of weights is:\", round(os.path.getsize('TransformerModel.pth')/1024**2,2), \"MB\" )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ul8Ulno-wyF","outputId":"df2c8277-ab00-4bd0-b6d2-d6d352cba88e"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":"The size of weights is: 124.13 MB\n"}]},{"cell_type":"code","source":"#loading weights\nsample_model = Transformer()\nsample_model.load_state_dict(torch.load('TransformerModel.pth'))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uk2RhMN6A2zL","outputId":"2f68a7f7-2416-4f30-f18f-3b1c8180b703"},"execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":["<All keys matched successfully>"]},"metadata":{}}]},{"cell_type":"code","source":"#structure of sample model (matches main model)\nsample_model.eval()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81wckqexBR4T","outputId":"62fa801d-8b31-4050-f822-529a47a0eacf"},"execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":["Transformer(\n","  (pre_block): PreBlock(\n","    (token_embedding_table): Embedding(117, 512)\n","    (position_embedding_table): Embedding(512, 512)\n","  )\n","  (blocks): Sequential(\n","    (0): Block(\n","      (attention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-15): 16 x Head(\n","            (key): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (query): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (value): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Sequential(\n","          (0): Linear(in_features=512, out_features=256, bias=True)\n","          (1): Tanh()\n","          (2): Linear(in_features=256, out_features=512, bias=True)\n","        )\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffd): FeedForward(\n","        (nonlin): Sequential(\n","          (0): Linear(in_features=512, out_features=3072, bias=True)\n","          (1): Tanh()\n","          (2): Linear(in_features=3072, out_features=512, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (1): Block(\n","      (attention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-15): 16 x Head(\n","            (key): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (query): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (value): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Sequential(\n","          (0): Linear(in_features=512, out_features=256, bias=True)\n","          (1): Tanh()\n","          (2): Linear(in_features=256, out_features=512, bias=True)\n","        )\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffd): FeedForward(\n","        (nonlin): Sequential(\n","          (0): Linear(in_features=512, out_features=3072, bias=True)\n","          (1): Tanh()\n","          (2): Linear(in_features=3072, out_features=512, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (2): Block(\n","      (attention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-15): 16 x Head(\n","            (key): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (query): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (value): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Sequential(\n","          (0): Linear(in_features=512, out_features=256, bias=True)\n","          (1): Tanh()\n","          (2): Linear(in_features=256, out_features=512, bias=True)\n","        )\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffd): FeedForward(\n","        (nonlin): Sequential(\n","          (0): Linear(in_features=512, out_features=3072, bias=True)\n","          (1): Tanh()\n","          (2): Linear(in_features=3072, out_features=512, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (3): Block(\n","      (attention): MultiHeadAttention(\n","        (heads): ModuleList(\n","          (0-15): 16 x Head(\n","            (key): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (query): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (value): Sequential(\n","              (0): Linear(in_features=512, out_features=16, bias=True)\n","              (1): Tanh()\n","              (2): Linear(in_features=16, out_features=32, bias=False)\n","            )\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (proj): Sequential(\n","          (0): Linear(in_features=512, out_features=256, bias=True)\n","          (1): Tanh()\n","          (2): Linear(in_features=256, out_features=512, bias=True)\n","        )\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (ffd): FeedForward(\n","        (nonlin): Sequential(\n","          (0): Linear(in_features=512, out_features=3072, bias=True)\n","          (1): Tanh()\n","          (2): Linear(in_features=3072, out_features=512, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (post_block): PostBlock(\n","    (fin_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (soft_score): Sequential(\n","      (0): Linear(in_features=512, out_features=58, bias=True)\n","      (1): Tanh()\n","      (2): Linear(in_features=58, out_features=117, bias=True)\n","    )\n","  )\n",")"]},"metadata":{}}]},{"cell_type":"code","source":"#transferring model to GPU and making a sample generation\nsample_model_GPU = sample_model.to(device)\ncontext = torch.tensor([[36]], dtype=torch.long, device=device)\n\nprint(decode(sample_model_GPU.generate(context, max_new_tokens=175)[0].tolist()))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmEcVrk1BU-B","outputId":"3e2bb2e2-7c08-4d32-a2b1-5cef954c759a"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":"Grover and touched around. “A second,” I said. “But it \n\nisn’t my fault. He thought I’m not get close, he’ll  turn sixteen.” \n\nChiron kept his eyes and he stood. “That’s not West\n"}]},{"cell_type":"markdown","source":"# Final Statistics:\n\n- System RAM used: 2.7GB\n- GPU RAM used: 35.5GB\n- Disk Space used: 26.5GB\n- Model Weights File Size: 124.13MB","metadata":{"id":"xghvDoY_-NT0"}}]}